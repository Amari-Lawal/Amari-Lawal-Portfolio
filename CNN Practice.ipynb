{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Practice "
   ]
  },
  {
   "source": [
    "### Google Cloud GPU use for computation\n",
    "Environment: Container Image (Dockerfile) on Google Cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good way for books and papers on Deep Learning\n",
    "#https://arxiv.org/abs/2009.05673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"C:/Users/user1/Desktop/Image Processing/CNN Practice/seg_train/seg_train\"\n",
    "DATA_URL_test = \"C:/Users/user1/Desktop/Image Processing/CNN Practice/seg_train/seg_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This directory was used for my docker container\n",
    "#DATA_URL = \"/tf/CNN Practice/seg_train/seg_train\"\n",
    "#DATA_URL_test = \"/tf/CNN Practice/seg_test/seg_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Shape\n",
    "s = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the code labels \n",
    "code = {\"buildings\": 0, \"forest\": 1,\"glacier\":2,\"mountain\":3,\"sea\":4,\"street\":5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What this program does is that it gets the folders from the url and then gets the image files using glob glob\n",
    "# Then in the collection of files I pick a single file then read it\n",
    "# Then I resize it ito shape (image, Width, Height,channel) ~ No need to specify channel\n",
    "# Then add the image array as a list in X_train to create small lists in lits which is a 2D array \n",
    "# Then add the code labels to y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the Image data from directory and resizes it to collective list of Training data with lables\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for folder in os.listdir(DATA_URL):\n",
    "    files = glob.glob(str(DATA_URL+\"/\"+folder+\"/*.jpg\"))\n",
    "    #print(f\"Training data of {folder}:\",len(files))\n",
    "    for file in files:\n",
    "        image = cv.imread(file)\n",
    "        image_array = cv.resize(image,(s,s))\n",
    "        X_train.append(list(image_array))\n",
    "        y_train.append(code[folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the Image data from directory and resizes it to collective list of Test data with labels\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for folder in os.listdir(DATA_URL_test):\n",
    "    files_1 = glob.glob(str(DATA_URL_test+\"/\"+folder+\"/*.jpg\"))\n",
    "    #print(f\"Training data of {folder}:\",len(files))\n",
    "    for file_1 in files_1:\n",
    "        im = cv.imread(file_1)\n",
    "        image_array_1 = cv.resize(im,(s,s))\n",
    "        X_test.append(list(image_array_1))\n",
    "        y_test.append(code[folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets index and value by using enumerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcode(n):\n",
    "    for x,y in code.items():\n",
    "        if n == y:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualises the images with the corresponding code from training data\n",
    "plt.figure(figsize=(20,20))\n",
    "for n, i in enumerate(list(np.random.randint(0,len(X_train),36))) : \n",
    "    plt.subplot(6,6,n+1)\n",
    "    plt.imshow(X_train[i])    \n",
    "    plt.axis('off')\n",
    "    plt.title(getcode(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuslises the images with the corresponding code from test data\n",
    "plt.figure(figsize=(20,20))\n",
    "for m, j in enumerate(list(np.random.randint(0,len(X_test),36))):\n",
    "    plt.subplot(6,6,m+1)\n",
    "    plt.imshow(X_test[j])\n",
    "    plt.axis('off')\n",
    "    plt.title(getcode(y_test[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets them to numpy arrays\n",
    "X_train = np.array(X_train,dtype=np.float32)\n",
    "X_test = np.array(X_test,dtype=np.float32)\n",
    "y_train = np.array(y_train,dtype=np.float32)\n",
    "y_test = np.array(y_test,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "print(f'Bytes stored:{sys.getsizeof(X_train)} and 3.78GB')"
   ]
  },
  {
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data (150,150,3)\n",
    "# Padding adds fake white pixels on edge to make sure that it evenly analyzes each pixel\n",
    "# Strides \n",
    "#Kernels is the Shape in which it is reading (3,3)\n",
    "# Mostly deal with the square of numbers like 9,16,25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates Model with CNN model with Sequential API \n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(512,kernel_size=(3,3),activation='relu',input_shape=(s,s,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(256,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "# May want to add more layers to reduce image to smallest output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles the model\n",
    "model.compile(optimizer ='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,epochs=10,batch_size=50,validation_split = 0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OOM stands for \"out of memory\". Your GPU is running out of memory, so it can't allocate memory for this tensor. There are a few things you can do:\n",
    "\n",
    "#1. Decrease the number of filters in your Dense, Conv2D layers\n",
    "#2. Use a smaller batch_size (or increase steps_per_epoch and validation_steps)\n",
    "#3. Use grayscale images (you can use tf.image.rgb_to_grayscale)\n",
    "#4.Reduce the number of layers\n",
    "#5.Use MaxPooling2D layers after convolutional layers\n",
    "#6.Reduce the size of your images (you can use tf.image.resize for that)\n",
    "# 7. Use smaller float precision for your input, namely np.float32\n",
    "#8.If you're using a pre-trained model, freeze the first layers (like this)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd0439c2a83c42033a481f27b98b28ee42f26c2df1e03d0615c896c41381d75608c",
   "display_name": "Python 3.7.10 64-bit ('tensorflow-gpu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}